#!/usr/bin/env python3

import cv2
import depthai as dai
import numpy as np

import time

import zmq
SERVER_IP = "127.0.0.1"

context = zmq.Context()

#  Socket to talk to server
print("Connecting to serverâ€¦")
socket = context.socket(zmq.REQ)
socket.connect("tcp://{}:5556".format(SERVER_IP))
print("Connected to server")

THRESHOLD = 5000
BINS = 5

# Closer-in minimum depth, disparity range is doubled (from 95 to 190):
extended_disparity = True
# Better accuracy for longer distance, fractional disparity 32-levels:
subpixel = False
# Better handling for occlusions:
lr_check = True

# Create pipeline
pipeline = dai.Pipeline()

# Define sources and outputs
monoLeft = pipeline.create(dai.node.MonoCamera)
monoRight = pipeline.create(dai.node.MonoCamera)
depth = pipeline.create(dai.node.StereoDepth)
xout = pipeline.create(dai.node.XLinkOut)

xout.setStreamName("disparity")

# Properties
monoLeft.setResolution(dai.MonoCameraProperties.SensorResolution.THE_400_P)
monoLeft.setBoardSocket(dai.CameraBoardSocket.LEFT)
monoRight.setResolution(dai.MonoCameraProperties.SensorResolution.THE_400_P)
monoRight.setBoardSocket(dai.CameraBoardSocket.RIGHT)

# Create a node that will produce the depth map (using disparity output as it's easier to visualize depth this way)
depth.setDefaultProfilePreset(dai.node.StereoDepth.PresetMode.HIGH_DENSITY)
# Options: MEDIAN_OFF, KERNEL_3x3, KERNEL_5x5, KERNEL_7x7 (default)
depth.initialConfig.setMedianFilter(dai.MedianFilter.KERNEL_7x7)
depth.setLeftRightCheck(lr_check)
depth.setExtendedDisparity(extended_disparity)
depth.setSubpixel(subpixel)

# Linking
monoLeft.out.link(depth.left)
monoRight.out.link(depth.right)
depth.disparity.link(xout.input)

# Connect to device and start pipeline
with dai.Device(pipeline) as device:

    # Output queue will be used to get the disparity frames from the outputs defined above
    q = device.getOutputQueue(name="disparity", maxSize=4, blocking=False)

    while True:
        inDisparity = q.get()  # blocking call, will wait until a new data has arrived
        frame = inDisparity.getFrame()
        # Normalization for better visualization
        frame = (frame * (255 / depth.initialConfig.getMaxDisparity())).astype(np.uint8)
        hist = np.histogram(frame, bins=BINS, range=(0, 255))[0]
        #print(hist)
        if hist[-1] > THRESHOLD:
            #print("collision")
            # Send collision message to the robot
            socket.send(bytes("collision", "utf-8"))
            #  Get the reply.
            message = socket.recv()
            print(f"Received reply [ {message} ]")
        time.sleep(1/5)
        #breakpoint()

        #cv2.imshow("disparity", frame)

        # Available color maps: https://docs.opencv.org/3.4/d3/d50/group__imgproc__colormap.html
        #frame = cv2.applyColorMap(frame, cv2.COLORMAP_JET)
        #cv2.imshow("disparity_color", frame)

        #if cv2.waitKey(1) == ord('q'):
        #    break
